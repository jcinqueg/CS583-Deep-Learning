{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxlI3atRGj8B"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: John Cinquegrana\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu5fEWAuGj8F"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQV8h653H6oH"
      },
      "source": [
        "# GPU On Colab\n",
        "I used Google Colab to run this code, the following excerpt checks to make sure that the GPU acceleration Colab offers is operating correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svjEmJEiIFry",
        "outputId": "eb43d0ce-ec33-43db-823d-def010fb4458"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=9ee352c95a9d120f34940283413aee72aedbac25fe3c8e6c8d5242779d2a9ba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=36ed1a833c698175d67ea20a213f9a336b7503b07bde52be39bdddb9b3b40f22\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w71BgX5xGj8F"
      },
      "source": [
        "# 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg_ehnG6Gj8H"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX6lwl1GGj8H",
        "outputId": "35e45d99-e642-4420-be37-cf54f53c5b1c"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiPyZq1gGj8H"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhjswmAIGj8H",
        "outputId": "ed3192a9-efa3-43c3-e6c4-835c6f6764ed"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    # Function was too complicated to hold in lambda expression\n",
        "    def to_one_array(num):\n",
        "        ls = numpy.zeros(num_class)\n",
        "        ls[num] = 1\n",
        "        return ls\n",
        "    # Map function over y_train vector\n",
        "    return numpy.asarray( list(\n",
        "        map( to_one_array, y )\n",
        "    ))\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ_lrzszGj8I"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTXHGD9PGj8I"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noHjw1I_pB6O"
      },
      "source": [
        "Before we randomly partition the training and validation sets, We apply normalization to all of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh--1xWMpBO6",
        "outputId": "1255f841-4374-4e9d-af3f-b48165824440"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Just to make sure we create a simple summary of the data\n",
        "print(\"Train Maximum: {}\".format( numpy.amax( x_train ) ) )\n",
        "print(\"Train Minimum: {}\".format( numpy.amin( x_train ) ) )\n",
        "print(\"Test Maximum: {}\".format( numpy.amax( x_test ) ) )\n",
        "print(\"Test Maximum: {}\".format( numpy.amin( x_test ) ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Maximum: 1.0\n",
            "Train Minimum: 0.0\n",
            "Test Maximum: 1.0\n",
            "Test Maximum: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwHDIEY-Gj8I",
        "outputId": "448e3bab-f3f1-4a10-aa15-87154cfed5a4"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWAq3r7HGj8J"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my0BgLrcGj8J"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuCDbkYXSNU1"
      },
      "source": [
        "# Set up for the CNN\n",
        "\n",
        "My CNN is based off of the structure known as DenseNet. DenseNet acts much like ResNet using skips over layers to deal with the vanishing gradient problem, but has been known to be better with so-called *global details*. Since the CIFAR10 Database is basically a test of object recognition (since each class is defined by the object within), I though that a DenseNet would be good for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRlbiLCUqU0P"
      },
      "source": [
        "## Import Statements\n",
        "Within my code I obviously use both Keras and Tensorflow. I import different convolutional layers from Keras in order to use them effectively.\n",
        "\n",
        "If I get around to it I will also import modules from the kerastuners package in order to properly tune my hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZROVYDUqpzp",
        "outputId": "b4396f1d-8e7a-460d-84fd-4150cd40dc54"
      },
      "source": [
        "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, GlobalAveragePooling2D, Input, AveragePooling2D, Concatenate, Dropout\n",
        "from math import floor\n",
        "\n",
        "print( \"Import statements loaded\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import statements loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DNhxk4qtH0c"
      },
      "source": [
        "## Dense Layer operations\n",
        "We create a function *layers* the generate and return a set of layers used within dense blocks. This will later be used by the a dense block generating function. These layers are only used inside the dense blocks, this is basically one *step* of the algorithm inside of the dense blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hjGuX3at3l2"
      },
      "source": [
        "def bt_layers( left_input, number_filters, drop_rate ):\n",
        "  lay = BatchNormalization()( left_input )\n",
        "  lay = Activation( 'relu' )( lay )\n",
        "  lay = Conv2D( 4*number_filters, (1,1), padding='same', kernel_initializer='he_normal' )( lay )\n",
        "  lay = Dropout( drop_rate )( lay )\n",
        "  lay = BatchNormalization() ( lay )\n",
        "  lay = Activation('relu')( lay )\n",
        "  lay = Conv2D( number_filters, (3,3), padding='same', kernel_initializer='he_normal' )( lay )\n",
        "  lay = Dropout( drop_rate )( lay )\n",
        "  return lay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ohqteNKuyI"
      },
      "source": [
        "## Dense Block\n",
        "Here we make use of the function `dense_layers` as detailed above. We iteratively call this function and concatenate the result of previous layers in what is known as a *concatenation skip* or a *dense skip*. This is in contrast to the popular *add skip* used in the ResNet framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_EzH3D0LA4w"
      },
      "source": [
        "def make_dense_block( input, number_layers, growth_rate, drop_rate ):\n",
        "  for iter in range(number_layers):\n",
        "    next_output = bt_layers( input, growth_rate, drop_rate )\n",
        "    input = Concatenate()([next_output, input])\n",
        "  return input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPJkE1VfKOT-"
      },
      "source": [
        "## Transition Layers\n",
        "These layers are occur in between each Dense Block of code. Their main function is to perform downsampling and regularization. It is at this point that many DenseNets make use of the compression parameter $\\theta$ as describe in the original research paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiByTzwdKs4Z"
      },
      "source": [
        "# Transition Layers\n",
        "def trans_layers( input, theta, drop_rate ):\n",
        "  lay = BatchNormalization()( input )\n",
        "  number_filters = floor( theta * input.shape[-1] )\n",
        "\n",
        "  lay = Conv2D( number_filters, (1,1), padding='same', kernel_initializer='he_normal')( lay )\n",
        "  lay = Dropout( drop_rate )( lay )\n",
        "  lay = AveragePooling2D()( lay ) #Pooling defaults to 2\n",
        "  return lay\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nkU7x_fijhN"
      },
      "source": [
        "## Parameters\n",
        "Define global values that will be used throughout the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aEJOuTElt2W",
        "outputId": "65dadffa-d43e-488b-e126-5aaf4d7e85bb"
      },
      "source": [
        "# Simple Problem Definitions\n",
        "batch_size = 32 #I don't consider this a hyperparameter since it's solely based off GPU availability\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "hp_epochs = 16\n",
        "image_shape = x_tr.shape[1:]\n",
        "initial_learning_rate = 1e-3 #I don't change the learning rate, because of the scheduler and reducer\n",
        "\n",
        "\n",
        "print( \"Batch Size: {}\".format(batch_size) )\n",
        "print( \"Epochs: {}\".format(epochs) )\n",
        "print( \"The HyperParameters will be tuned over a max of {} epochs.\".format(hp_epochs))\n",
        "print( \"Our CNN will work with the shape {}\".format( image_shape ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size: 32\n",
            "Epochs: 30\n",
            "The HyperParameters will be tuned over a max of 16 epochs.\n",
            "Our CNN will work with the shape (32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgYnYor1PyqO"
      },
      "source": [
        "# The Fun Part\n",
        "We use the parameters we have just defined to build the densenet model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRbaZp2VZQ54"
      },
      "source": [
        "## Build Model Function\n",
        "Because we're using keras-tuners to tune the hyperparameters, we need a `build_model` function. keras-tuners will take this function and optimize all the hyperparameters we take out of it to be the best.\n",
        "The build_model function returns a full DenseNet CNN when it is called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsZKFTg2ZkqI"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "def build_model(HP):\n",
        "  theta = HP.Float('theta', 0.2, 0.6, step=0.1)\n",
        "  growth_rate = HP.Int('growth_rate', 8, 20, step=2)\n",
        "  bottleneck_layers = HP.Int('bottleneck_layers', 12, 20, step=2)\n",
        "  dense_blocks = HP.Int('dense_blocks', 2, 4)\n",
        "  drop_rate = HP.Float('drop_rate', 0.1, 0.5)\n",
        "  initial_filters = growth_rate*2\n",
        "\n",
        "  # This initial layers that will deal with the input\n",
        "  initial_layer = Input( shape=image_shape )\n",
        "  layers = BatchNormalization()( initial_layer )\n",
        "  layers = Activation( 'relu' )( layers )\n",
        "  layers = Conv2D( initial_filters, (3,3), padding='same', kernel_initializer='he_normal' )( layers )\n",
        "  layers = Concatenate()([initial_layer, layers])\n",
        "\n",
        "  # Create the Dense Blocks\n",
        "  for _ in range( dense_blocks ):\n",
        "    layers = make_dense_block(layers, bottleneck_layers, growth_rate, drop_rate)\n",
        "    layers = trans_layers( layers, theta, drop_rate )\n",
        "\n",
        "  # The final layers of the CNN\n",
        "  layers = GlobalAveragePooling2D()( layers )\n",
        "  layers = Dense( num_classes )( layers )\n",
        "  final_layer = Activation( 'softmax' )( layers )\n",
        "\n",
        "  model = Model(initial_layer, final_layer)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.RMSprop( learning_rate=initial_learning_rate ), #I've been told RMSProp works well for DenseNets\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlHMoEmvbwNo"
      },
      "source": [
        "## Generate callbacks\n",
        "The Callbacks of a keras model are called every single Epoch. I use them to schedule/change the learning rate, and to stop early and ease computation drain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLKpkKTtcDuy"
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "def gen_callbacks(inital_lr, early_delta=0.01):\n",
        "  reducer = ReduceLROnPlateau(factor=0.3,\n",
        "                            cooldown=0,\n",
        "                            verbose=1, #Give us update messages\n",
        "                            patience=4,\n",
        "                            min_lr=0.5e-6\n",
        "                            )\n",
        "\n",
        "  def schedule(epoch, cur_lr):\n",
        "      lr = inital_lr\n",
        "      if epoch > (epochs*0.9):\n",
        "          lr *= 0.5e-2\n",
        "      elif epoch > (epochs*0.8):\n",
        "          lr *= 1e-2\n",
        "      elif epoch > (epochs*0.6):\n",
        "          lr *= 1e-1\n",
        "      elif epoch > (epochs*0.4):\n",
        "          lr *= 0.5\n",
        "      result = min(lr, cur_lr)\n",
        "      print('Learning rate: ', result)\n",
        "      return result\n",
        "\n",
        "  scheduler = LearningRateScheduler(schedule)\n",
        "\n",
        "  early_stop = EarlyStopping(min_delta=early_delta, patience=3, verbose=0,\n",
        "    mode='min')\n",
        "\n",
        "  return [scheduler, reducer, early_stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDk0mA3JDGUq"
      },
      "source": [
        "## Data Augmentation\n",
        "We perform data augmentation by using Keras's built in ImageGenerator. The Generator will randomly change data being sent into the neural net to help reduce overfitting and pseudo-increase the sample size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExSTmj1mDIoP"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit( x_tr )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atgd8lVOiT1d"
      },
      "source": [
        "## Train HyperParameters with KerasTuner\n",
        "Using KerasTuner we train all the hyperparameters using the HyperBand search algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0BW_zvjiDc0",
        "outputId": "d80cce65-4cca-4b24-8466-fcf3efa40fc3"
      },
      "source": [
        "# Train the HyperParameters with KerasTuner\n",
        "\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import Hyperband\n",
        "\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=hp_epochs)\n",
        "\n",
        "cb = gen_callbacks( initial_learning_rate )\n",
        "\n",
        "tuner.search(datagen.flow(x_tr, y_tr, batch_size=batch_size),\n",
        "    batch_size=batch_size, verbose=1, epochs=hp_epochs, validation_data=(x_val, y_val),\n",
        "    callbacks=cb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 33m 56s]\n",
            "val_accuracy: 0.8208000063896179\n",
            "\n",
            "Best val_accuracy So Far: 0.8471999764442444\n",
            "Total elapsed time: 07h 49m 59s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ZLFm4fmV9t"
      },
      "source": [
        "## Hyperparameters are set\n",
        "Now that we have all the hyperparameters, let us take a look at them. Unfortunately keras-tuners doesn't allow us to look at the history of the `model.fit` results, however we can see a summary of the hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTd8K3yumy8E",
        "outputId": "2e72eb8d-dc2a-47d9-c273-4bef9d5918d0"
      },
      "source": [
        "# Show the results of the tuner\n",
        "tuner.results_summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.30000000000000004\n",
            "growth_rate: 14\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.12530065427527037\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 6\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 6d4fb7de9a08cf658eccc8cc9c987437\n",
            "Score: 0.8471999764442444\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.4000000000000001\n",
            "growth_rate: 10\n",
            "bottleneck_layers: 12\n",
            "dense_blocks: 4\n",
            "drop_rate: 0.21477025247089193\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.8208000063896179\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.30000000000000004\n",
            "growth_rate: 12\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.15310972703932527\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 6\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 21c511aa74baf0e9d9e8f9135ba3ce7a\n",
            "Score: 0.8202999830245972\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.6000000000000001\n",
            "growth_rate: 12\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.17861803456280723\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 6\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: a00a970282c498cd18cb48398e36717c\n",
            "Score: 0.8152999877929688\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.4000000000000001\n",
            "growth_rate: 14\n",
            "bottleneck_layers: 12\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.2022622914447353\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 6\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 748bd40c6049e879d33665af7c0fcdca\n",
            "Score: 0.7853000164031982\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.6000000000000001\n",
            "growth_rate: 12\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 2\n",
            "drop_rate: 0.21419068760631862\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.7598999738693237\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.30000000000000004\n",
            "growth_rate: 14\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.12530065427527037\n",
            "tuner/epochs: 6\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7419999837875366\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.30000000000000004\n",
            "growth_rate: 12\n",
            "bottleneck_layers: 18\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.15310972703932527\n",
            "tuner/epochs: 6\n",
            "tuner/initial_epoch: 2\n",
            "tuner/bracket: 2\n",
            "tuner/round: 1\n",
            "tuner/trial_id: b6756626de1bf7dab6066c48e73c81e9\n",
            "Score: 0.7364000082015991\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.4000000000000001\n",
            "growth_rate: 14\n",
            "bottleneck_layers: 12\n",
            "dense_blocks: 3\n",
            "drop_rate: 0.2022622914447353\n",
            "tuner/epochs: 6\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 1\n",
            "tuner/round: 0\n",
            "Score: 0.7268000245094299\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "theta: 0.5000000000000001\n",
            "growth_rate: 8\n",
            "bottleneck_layers: 14\n",
            "dense_blocks: 4\n",
            "drop_rate: 0.43081094853539426\n",
            "tuner/epochs: 16\n",
            "tuner/initial_epoch: 0\n",
            "tuner/bracket: 0\n",
            "tuner/round: 0\n",
            "Score: 0.7250000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOcOvoyGj8K"
      },
      "source": [
        "# 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNFcK0CsGj8L"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmvsShSBGj8L",
        "outputId": "448af43f-8b8a-4719-e016-e80dfc8fc932"
      },
      "source": [
        "# Get the best model that the tuner trained\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "# Warnings occur in all of the hyperparameters that were either assumed by the model, or set as static and not trained\n",
        "# To my knowledge there is no way to remove the warnings\n",
        "best_model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 3)    12          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 3)    0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 28)   784         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 31)   0           input_1[0][0]                    \n",
            "                                                                 conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 31)   124         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 31)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 56)   1792        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 56)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 56)   224         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 56)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 14)   7070        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 14)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 45)   0           dropout_1[0][0]                  \n",
            "                                                                 concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 45)   180         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 45)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 56)   2576        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 56)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 56)   224         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 56)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 14)   7070        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 14)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 59)   0           dropout_3[0][0]                  \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 59)   236         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 59)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 56)   3360        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 56)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 56)   224         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 56)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 14)   7070        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 14)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 73)   0           dropout_5[0][0]                  \n",
            "                                                                 concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 73)   292         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 73)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 56)   4144        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 56)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 56)   224         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 56)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 14)   7070        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 14)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 87)   0           dropout_7[0][0]                  \n",
            "                                                                 concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 87)   348         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 87)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 56)   4928        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 56)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 56)   224         dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 56)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 14)   7070        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 14)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 101)  0           dropout_9[0][0]                  \n",
            "                                                                 concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 101)  404         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 101)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 56)   5712        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 56)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 56)   224         dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 56)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 14)   7070        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 14)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 115)  0           dropout_11[0][0]                 \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 115)  460         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 115)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 56)   6496        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 56)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 56)   224         dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 56)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 14)   7070        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 14)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 129)  0           dropout_13[0][0]                 \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 129)  516         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 129)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 56)   7280        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 56)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 56)   224         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 56)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 14)   7070        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 14)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 143)  0           dropout_15[0][0]                 \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 143)  572         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 143)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 56)   8064        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 56)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 56)   224         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 56)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 14)   7070        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 32, 32, 14)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 157)  0           dropout_17[0][0]                 \n",
            "                                                                 concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 157)  628         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 157)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 56)   8848        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 32, 32, 56)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 56)   224         dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 56)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 14)   7070        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 32, 32, 14)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 171)  0           dropout_19[0][0]                 \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 171)  684         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 171)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 56)   9632        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32, 32, 56)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 56)   224         dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 56)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 14)   7070        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 32, 32, 14)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 185)  0           dropout_21[0][0]                 \n",
            "                                                                 concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 185)  740         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 185)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 56)   10416       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 32, 32, 56)   0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 56)   224         dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 56)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 14)   7070        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32, 32, 14)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 199)  0           dropout_23[0][0]                 \n",
            "                                                                 concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 199)  796         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 199)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 56)   11200       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 32, 32, 56)   0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 56)   224         dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 56)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 14)   7070        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 32, 32, 14)   0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 213)  0           dropout_25[0][0]                 \n",
            "                                                                 concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 32, 213)  852         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 32, 32, 213)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 56)   11984       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 32, 32, 56)   0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 56)   224         dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 56)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 14)   7070        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 32, 32, 14)   0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 227)  0           dropout_27[0][0]                 \n",
            "                                                                 concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 227)  908         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 227)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 56)   12768       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 32, 32, 56)   0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 56)   224         dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 56)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 14)   7070        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 32, 32, 14)   0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 241)  0           dropout_29[0][0]                 \n",
            "                                                                 concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 241)  964         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 241)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 56)   13552       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 32, 32, 56)   0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 32, 56)   224         dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 56)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 14)   7070        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 32, 32, 14)   0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 255)  0           dropout_31[0][0]                 \n",
            "                                                                 concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 32, 255)  1020        concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 255)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 56)   14336       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 32, 32, 56)   0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 32, 32, 56)   224         dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 56)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 14)   7070        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 32, 32, 14)   0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 32, 32, 269)  0           dropout_33[0][0]                 \n",
            "                                                                 concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 32, 32, 269)  1076        concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 269)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 56)   15120       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 32, 32, 56)   0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 32, 32, 56)   224         dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 32, 32, 56)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 14)   7070        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 32, 32, 14)   0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 32, 32, 283)  0           dropout_35[0][0]                 \n",
            "                                                                 concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 32, 32, 283)  1132        concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 84)   23856       batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 32, 32, 84)   0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 84)   0           dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 16, 16, 84)   336         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 84)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 56)   4760        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 16, 16, 56)   0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 16, 16, 56)   224         dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 56)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 14)   7070        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 16, 16, 14)   0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 98)   0           dropout_38[0][0]                 \n",
            "                                                                 average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 16, 16, 98)   392         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 98)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 56)   5544        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 16, 16, 56)   0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 16, 16, 56)   224         dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 16, 16, 56)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 14)   7070        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 16, 16, 14)   0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 112)  0           dropout_40[0][0]                 \n",
            "                                                                 concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 16, 16, 112)  448         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 16, 16, 112)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 56)   6328        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 16, 16, 56)   0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 16, 16, 56)   224         dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 16, 16, 56)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 14)   7070        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 16, 16, 14)   0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 126)  0           dropout_42[0][0]                 \n",
            "                                                                 concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 126)  504         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 16, 16, 126)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 56)   7112        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 16, 16, 56)   0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 56)   224         dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 16, 16, 56)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 14)   7070        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 16, 16, 14)   0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 140)  0           dropout_44[0][0]                 \n",
            "                                                                 concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 140)  560         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 16, 16, 140)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 56)   7896        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 16, 16, 56)   0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 56)   224         dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 56)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 14)   7070        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 16, 16, 14)   0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 154)  0           dropout_46[0][0]                 \n",
            "                                                                 concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 154)  616         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 154)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 56)   8680        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 16, 16, 56)   0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 56)   224         dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 56)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 14)   7070        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 16, 16, 14)   0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 168)  0           dropout_48[0][0]                 \n",
            "                                                                 concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 168)  672         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 168)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 56)   9464        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 16, 16, 56)   0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 16, 16, 56)   224         dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 56)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 14)   7070        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 16, 16, 14)   0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 182)  0           dropout_50[0][0]                 \n",
            "                                                                 concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 16, 16, 182)  728         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 182)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 56)   10248       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 16, 16, 56)   0           conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 16, 16, 56)   224         dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 16, 16, 56)   0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 14)   7070        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 16, 16, 14)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 196)  0           dropout_52[0][0]                 \n",
            "                                                                 concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 196)  784         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 16, 16, 196)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 56)   11032       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 16, 16, 56)   0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 56)   224         dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 16, 16, 56)   0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 14)   7070        activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 16, 16, 14)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 210)  0           dropout_54[0][0]                 \n",
            "                                                                 concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 210)  840         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 16, 16, 210)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 56)   11816       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 16, 16, 56)   0           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 56)   224         dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 16, 16, 56)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 14)   7070        activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 16, 16, 14)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 224)  0           dropout_56[0][0]                 \n",
            "                                                                 concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 224)  896         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 16, 16, 224)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 56)   12600       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 16, 16, 56)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 56)   224         dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 16, 16, 56)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 14)   7070        activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 16, 16, 14)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 238)  0           dropout_58[0][0]                 \n",
            "                                                                 concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 16, 16, 238)  952         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 16, 16, 238)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 56)   13384       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 16, 16, 56)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 16, 16, 56)   224         dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 16, 16, 56)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 14)   7070        activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 16, 16, 14)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 252)  0           dropout_60[0][0]                 \n",
            "                                                                 concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 252)  1008        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 16, 16, 252)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 56)   14168       activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 56)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 56)   224         dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 56)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 14)   7070        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 16, 16, 14)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 266)  0           dropout_62[0][0]                 \n",
            "                                                                 concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 266)  1064        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 266)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 56)   14952       activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 16, 16, 56)   0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 56)   224         dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 56)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 14)   7070        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 16, 16, 14)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 16, 16, 280)  0           dropout_64[0][0]                 \n",
            "                                                                 concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 280)  1120        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 280)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 56)   15736       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 16, 16, 56)   0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 56)   224         dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 56)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 14)   7070        activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 16, 16, 14)   0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 16, 16, 294)  0           dropout_66[0][0]                 \n",
            "                                                                 concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 294)  1176        concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 294)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 56)   16520       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 16, 16, 56)   0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 16, 16, 56)   224         dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 56)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 14)   7070        activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 16, 16, 14)   0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 16, 16, 308)  0           dropout_68[0][0]                 \n",
            "                                                                 concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 16, 16, 308)  1232        concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 308)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 16, 16, 56)   17304       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 16, 16, 56)   0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 16, 16, 56)   224         dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 56)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 16, 16, 14)   7070        activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 16, 16, 14)   0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 16, 16, 322)  0           dropout_70[0][0]                 \n",
            "                                                                 concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 16, 16, 322)  1288        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 16, 16, 322)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 56)   18088       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 16, 16, 56)   0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 16, 16, 56)   224         dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 16, 16, 56)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 14)   7070        activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 16, 16, 14)   0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 16, 16, 336)  0           dropout_72[0][0]                 \n",
            "                                                                 concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 16, 16, 336)  1344        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 100)  33700       batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 16, 16, 100)  0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 100)    0           dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 100)    400         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 8, 8, 100)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 56)     5656        activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 8, 8, 56)     0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 56)     224         dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 8, 8, 56)     0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 14)     7070        activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 8, 8, 14)     0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 114)    0           dropout_75[0][0]                 \n",
            "                                                                 average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 114)    456         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 114)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 56)     6440        activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 8, 8, 56)     0           conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 56)     224         dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 56)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 14)     7070        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 8, 8, 14)     0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 128)    0           dropout_77[0][0]                 \n",
            "                                                                 concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 128)    512         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 128)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 56)     7224        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 8, 8, 56)     0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 56)     224         dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 56)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 14)     7070        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 8, 8, 14)     0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 142)    0           dropout_79[0][0]                 \n",
            "                                                                 concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 142)    568         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 142)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 56)     8008        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 8, 8, 56)     0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 56)     224         dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 56)     0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 14)     7070        activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 8, 8, 14)     0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 156)    0           dropout_81[0][0]                 \n",
            "                                                                 concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 156)    624         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 156)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 56)     8792        activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 8, 8, 56)     0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 56)     224         dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 56)     0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 14)     7070        activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 8, 8, 14)     0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 170)    0           dropout_83[0][0]                 \n",
            "                                                                 concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 170)    680         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 170)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 56)     9576        activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 8, 8, 56)     0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 56)     224         dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 56)     0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 14)     7070        activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 8, 8, 14)     0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 184)    0           dropout_85[0][0]                 \n",
            "                                                                 concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 184)    736         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 184)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 56)     10360       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 8, 8, 56)     0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 56)     224         dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 56)     0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 14)     7070        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 8, 8, 14)     0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 198)    0           dropout_87[0][0]                 \n",
            "                                                                 concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 198)    792         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 198)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 56)     11144       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 8, 8, 56)     0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 56)     224         dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 56)     0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 14)     7070        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 8, 8, 14)     0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 212)    0           dropout_89[0][0]                 \n",
            "                                                                 concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 212)    848         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 212)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 56)     11928       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 8, 8, 56)     0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 56)     224         dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 56)     0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 14)     7070        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 8, 8, 14)     0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 226)    0           dropout_91[0][0]                 \n",
            "                                                                 concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 226)    904         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 226)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 56)     12712       activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 8, 8, 56)     0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 56)     224         dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 56)     0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 14)     7070        activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 8, 8, 14)     0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 240)    0           dropout_93[0][0]                 \n",
            "                                                                 concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 240)    960         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 240)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 56)     13496       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 8, 8, 56)     0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 56)     224         dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 8, 8, 56)     0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 14)     7070        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 8, 8, 14)     0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 254)    0           dropout_95[0][0]                 \n",
            "                                                                 concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 254)    1016        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 8, 8, 254)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 56)     14280       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 8, 8, 56)     0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 56)     224         dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 8, 8, 56)     0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 14)     7070        activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 8, 8, 14)     0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 8, 8, 268)    0           dropout_97[0][0]                 \n",
            "                                                                 concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 8, 8, 268)    1072        concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 8, 8, 268)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 56)     15064       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 8, 8, 56)     0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 8, 8, 56)     224         dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 8, 8, 56)     0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 8, 8, 14)     7070        activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 8, 8, 14)     0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 8, 8, 282)    0           dropout_99[0][0]                 \n",
            "                                                                 concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 8, 8, 282)    1128        concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 8, 8, 282)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 8, 8, 56)     15848       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 8, 8, 56)     0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 8, 8, 56)     224         dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 56)     0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 8, 8, 14)     7070        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 8, 8, 14)     0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 8, 8, 296)    0           dropout_101[0][0]                \n",
            "                                                                 concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 8, 8, 296)    1184        concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 8, 8, 296)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 8, 8, 56)     16632       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 8, 8, 56)     0           conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 8, 8, 56)     224         dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 8, 8, 56)     0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 8, 8, 14)     7070        activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 8, 8, 14)     0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 8, 8, 310)    0           dropout_103[0][0]                \n",
            "                                                                 concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 310)    1240        concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 8, 8, 310)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 8, 8, 56)     17416       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 8, 8, 56)     0           conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 56)     224         dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 8, 8, 56)     0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 14)     7070        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 8, 8, 14)     0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 8, 8, 324)    0           dropout_105[0][0]                \n",
            "                                                                 concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 324)    1296        concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 324)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 56)     18200       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 8, 8, 56)     0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 56)     224         dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 56)     0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 14)     7070        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 8, 8, 14)     0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 8, 8, 338)    0           dropout_107[0][0]                \n",
            "                                                                 concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 8, 8, 338)    1352        concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 338)    0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 8, 8, 56)     18984       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 8, 8, 56)     0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 8, 8, 56)     224         dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 8, 8, 56)     0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 8, 8, 14)     7070        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 8, 8, 14)     0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 8, 8, 352)    0           dropout_109[0][0]                \n",
            "                                                                 concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 8, 8, 352)    1408        concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 8, 8, 105)    37065       batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 8, 8, 105)    0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 105)    0           dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 105)          0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           1060        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 10)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,115,021\n",
            "Trainable params: 1,086,433\n",
            "Non-trainable params: 28,588\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAfYneX9nqW-"
      },
      "source": [
        "## Data augmentation\n",
        "Create another data generator, this time acting on all of `x_train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuTomk7AoDSA"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit( x_train )"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7pgFZ7n4TO"
      },
      "source": [
        "## Full Training\n",
        "We have everything we need to train the actual model again. the callbacks will be mostly the same, but we must generate them with a different number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrBYzzDNGj8L",
        "outputId": "11dd3529-e122-47a8-a2c4-3977f2909f7c"
      },
      "source": [
        "# The number of epochs listed before would have taken too long to train, so we lower it for the actual model\n",
        "epochs = 20\n",
        "\n",
        "reducer = ReduceLROnPlateau(factor=0.3,\n",
        "                            cooldown=0,\n",
        "                            verbose=1, #Give us update messages\n",
        "                            patience=4,\n",
        "                            min_lr=0.5e-6,\n",
        "                            monitor='loss'\n",
        "                            )\n",
        "\n",
        "def schedule(epoch, cur_lr):\n",
        "    lr = 1e-3\n",
        "    if epoch > (epochs*0.9):\n",
        "        lr *= 0.5e-2\n",
        "    elif epoch > (epochs*0.8):\n",
        "        lr *= 1e-2\n",
        "    elif epoch > (epochs*0.6):\n",
        "        lr *= 1e-1\n",
        "    elif epoch > (epochs*0.4):\n",
        "        lr *= 0.5\n",
        "    result = min(lr, cur_lr)\n",
        "    print('Learning rate: ', result)\n",
        "    return result\n",
        "\n",
        "scheduler = LearningRateScheduler(schedule)\n",
        "\n",
        "early_stop = EarlyStopping(min_delta=0.01, patience=3, verbose=0,\n",
        "  mode='min', monitor='loss')\n",
        "\n",
        "cb = [scheduler, reducer, early_stop]\n",
        "\n",
        "history = best_model.fit(datagen.flow(x_train, y_train_vec, batch_size=batch_size),\n",
        "    batch_size=batch_size, verbose=1, epochs=epochs,\n",
        "    callbacks=cb)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.5388 - accuracy: 0.8147\n",
            "Epoch 2/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.5004 - accuracy: 0.8270\n",
            "Epoch 3/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.4743 - accuracy: 0.8378\n",
            "Epoch 4/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.4448 - accuracy: 0.8476\n",
            "Epoch 5/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.4253 - accuracy: 0.8529\n",
            "Epoch 6/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.4042 - accuracy: 0.8608\n",
            "Epoch 7/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.3852 - accuracy: 0.8676\n",
            "Epoch 8/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.3689 - accuracy: 0.8732\n",
            "Epoch 9/20\n",
            "Learning rate:  0.001\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.3557 - accuracy: 0.8761\n",
            "Epoch 10/20\n",
            "Learning rate:  0.0005\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.2926 - accuracy: 0.8993\n",
            "Epoch 11/20\n",
            "Learning rate:  0.0005\n",
            "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2693 - accuracy: 0.9070\n",
            "Epoch 12/20\n",
            "Learning rate:  0.0005\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.2598 - accuracy: 0.9107\n",
            "Epoch 13/20\n",
            "Learning rate:  0.0005\n",
            "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2527 - accuracy: 0.9126\n",
            "Epoch 14/20\n",
            "Learning rate:  0.0001\n",
            "1563/1563 [==============================] - 240s 153ms/step - loss: 0.2108 - accuracy: 0.9273\n",
            "Epoch 15/20\n",
            "Learning rate:  9.999999747378752e-05\n",
            "1563/1563 [==============================] - 240s 153ms/step - loss: 0.1985 - accuracy: 0.9318\n",
            "Epoch 16/20\n",
            "Learning rate:  9.999999747378752e-05\n",
            "1563/1563 [==============================] - 242s 155ms/step - loss: 0.1923 - accuracy: 0.9339\n",
            "Epoch 17/20\n",
            "Learning rate:  9.999999747378752e-05\n",
            "1563/1563 [==============================] - 241s 154ms/step - loss: 0.1876 - accuracy: 0.9341\n",
            "Epoch 18/20\n",
            "Learning rate:  1e-05\n",
            "1563/1563 [==============================] - 240s 153ms/step - loss: 0.1802 - accuracy: 0.9377\n",
            "Epoch 19/20\n",
            "Learning rate:  9.999999747378752e-06\n",
            "1563/1563 [==============================] - 240s 153ms/step - loss: 0.1807 - accuracy: 0.9361\n",
            "Epoch 20/20\n",
            "Learning rate:  5e-06\n",
            "1563/1563 [==============================] - 240s 154ms/step - loss: 0.1771 - accuracy: 0.9377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdgVVo-3nBqH"
      },
      "source": [
        "Note that an early stopping callback is used. If you run this model yourself, espeically with a higher epoch value, it's very possible your model may stop training before the final epoch value is hit. This is normal.\n",
        "\n",
        "## A Test Accuracy Above 90%!!\n",
        "Quite honestly I spent a lot of time researching new models, and training this took up around 9 hours of my day. I am quite proud of how the model performed, and I am so excited to have broken the 90% barrier.\n",
        "\n",
        "## History\n",
        "Let's create a nifty little graph showing the history of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qUeP5tBFojEX",
        "outputId": "60167355-865f-4834-a35e-a50d1169afb6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCMKyhAbGj8L"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4kl48YiGj8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4395675f-5099-4f08-db25-4a97a5c8fba4"
      },
      "source": [
        "loss_and_acc = best_model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 12s 30ms/step - loss: 0.2939 - accuracy: 0.9144\n",
            "loss = 0.2938983142375946\n",
            "accuracy = 0.9143999814987183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x78gDJg45I0L"
      },
      "source": [
        "## Final Results\n",
        "\n",
        "We reached an accuracy of `93.77` on the testing set and an accuracy of `91.44` on the training set. I do suspect there is some amount of overfitting occuring despite my attempts to combat it.   \n",
        "Overall I believe the accuracy is quite high; while a better network can obviously be made, the DenseNet structure seemed quite suited to the 10-class classification task."
      ]
    }
  ]
}