{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM2: Numerical Optimization for Logistic Regression.\n",
    "\n",
    "### Name: John Cinquegrana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf)\n",
    "\n",
    "2. Read, complete, and run my code.\n",
    "\n",
    "3. **Implement mini-batch SGD** and evaluate the performance.\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM2/HM2.html\n",
    "\n",
    "\n",
    "## Grading criteria:\n",
    "\n",
    "1. When computing the ```gradient``` and ```objective function value``` using a batch of samples, use **matrix-vector multiplication** rather than a FOR LOOP of **vector-vector multiplications**.\n",
    "\n",
    "2. Plot ```objective function value``` against ```epochs```. In the plot, compare GD, SGD, and MB-SGD (with $b=8$ and $b=64$). The plot must look reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of x: (768, 8)\nShape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of x_train: (640, 8)\nShape of x_test: (128, 8)\nShape of y_train: (640, 1)\nShape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to transform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test mean = \n[[ 0.03889547  0.06288502  0.02533652  0.00137953 -0.0082033  -0.12354753\n   0.03181991 -0.04619112]]\ntest std = \n[[1.05761867 0.96509514 0.97386985 1.03173805 0.84055198 0.92144758\n  0.95093464 0.90026499]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of x_train: (640, 9)\nShape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression model\n",
    "\n",
    "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\nObjective value at t=1 is 0.5821035853905387\nObjective value at t=2 is 0.5376648053699417\nObjective value at t=3 is 0.5138087440379963\nObjective value at t=4 is 0.4988654560534071\nObjective value at t=5 is 0.4886862473180537\nObjective value at t=6 is 0.4813893541773575\nObjective value at t=7 is 0.47597707174264603\nObjective value at t=8 is 0.471862608560417\nObjective value at t=9 is 0.4686753429990011\nObjective value at t=10 is 0.4661689860608954\nObjective value at t=11 is 0.4641735856563576\nObjective value at t=12 is 0.46256840147227785\nObjective value at t=13 is 0.4612656285628936\nObjective value at t=14 is 0.4602001672711141\nObjective value at t=15 is 0.45932295414211793\nObjective value at t=16 is 0.4585964841872069\nObjective value at t=17 is 0.4579917301487448\nObjective value at t=18 is 0.45748597853270756\nObjective value at t=19 is 0.4570612820300253\nObjective value at t=20 is 0.4567033350595772\nObjective value at t=21 is 0.4564006450764559\nObjective value at t=22 is 0.456143913976888\nObjective value at t=23 is 0.4559255709229935\nObjective value at t=24 is 0.45573941574539356\nObjective value at t=25 is 0.45558034407865766\nObjective value at t=26 is 0.4554441335847413\nObjective value at t=27 is 0.4553272763064196\nObjective value at t=28 is 0.45522684618932474\nObjective value at t=29 is 0.45514039365463455\nObjective value at t=30 is 0.45506586115070113\nObjective value at t=31 is 0.4550015151002515\nObjective value at t=32 is 0.4549458907532505\nObjective value at t=33 is 0.45489774726644927\nObjective value at t=34 is 0.45485603093741556\nObjective value at t=35 is 0.4548198449786654\nObjective value at t=36 is 0.4547884245657003\nObjective value at t=37 is 0.45476111615953624\nObjective value at t=38 is 0.45473736031017997\nObjective value at t=39 is 0.4547166773074289\nObjective value at t=40 is 0.45469865517039365\nObjective value at t=41 is 0.45468293956546607\nObjective value at t=42 is 0.45466922532022547\nObjective value at t=43 is 0.4546572492626153\nObjective value at t=44 is 0.45464678416414805\nObjective value at t=45 is 0.4546376336055904\nObjective value at t=46 is 0.4546296276156065\nObjective value at t=47 is 0.4546226189587838\nObjective value at t=48 is 0.45461647997057625\nObjective value at t=49 is 0.4546110998539487\nObjective value at t=50 is 0.45460638236663353\nObjective value at t=51 is 0.4546022438395451\nObjective value at t=52 is 0.45459861147649194\nObjective value at t=53 is 0.45459542189327395\nObjective value at t=54 is 0.45459261986084804\nObjective value at t=55 is 0.4545901572227451\nObjective value at t=56 is 0.4545879919615018\nObjective value at t=57 is 0.45458608739271894\nObjective value at t=58 is 0.45458441146857453\nObjective value at t=59 is 0.454582936175333\nObjective value at t=60 is 0.45458163701167537\nObjective value at t=61 is 0.4545804925366026\nObjective value at t=62 is 0.4545794839773002\nObjective value at t=63 is 0.4545785948887312\nObjective value at t=64 is 0.4545778108579055\nObjective value at t=65 is 0.45457711924676597\nObjective value at t=66 is 0.4545765089684925\nObjective value at t=67 is 0.45457597029274155\nObjective value at t=68 is 0.4545754946759709\nObjective value at t=69 is 0.4545750746135199\nObjective value at t=70 is 0.4545747035105793\nObjective value at t=71 is 0.4545743755695712\nObjective value at t=72 is 0.4545740856917945\nObjective value at t=73 is 0.454573829391484\nObjective value at t=74 is 0.45457360272067304\nObjective value at t=75 is 0.4545734022034702\nObjective value at t=76 is 0.4545732247785402\nObjective value at t=77 is 0.4545730677487412\nObjective value at t=78 is 0.4545729287370065\nObjective value at t=79 is 0.4545728056476797\nObjective value at t=80 is 0.454572696632613\nObjective value at t=81 is 0.4545726000614294\nObjective value at t=82 is 0.4545725144954266\nObjective value at t=83 is 0.45457243866466734\nObjective value at t=84 is 0.45457237144785767\nObjective value at t=85 is 0.45457231185466923\nObjective value at t=86 is 0.45457225901020015\nObjective value at t=87 is 0.45457221214131316\nObjective value at t=88 is 0.4545721705646182\nObjective value at t=89 is 0.45457213367589777\nObjective value at t=90 is 0.45457210094080036\nObjective value at t=91 is 0.4545720718866442\nObjective value at t=92 is 0.45457204609519963\nObjective value at t=93 is 0.45457202319632833\nObjective value at t=94 is 0.45457200286237776\nObjective value at t=95 is 0.4545719848032391\nObjective value at t=96 is 0.45457196876198863\nObjective value at t=97 is 0.45457195451104254\nObjective value at t=98 is 0.45457194184876354\nObjective value at t=99 is 0.45457193059646656\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective value at epoch t=0 is 0.5273529165943426\n",
      "Objective value at epoch t=1 is 0.5039090867325674\n",
      "Objective value at epoch t=2 is 0.49828007188242635\n",
      "Objective value at epoch t=3 is 0.4924446018100972\n",
      "Objective value at epoch t=4 is 0.48961589833361235\n",
      "Objective value at epoch t=5 is 0.48661682685731655\n",
      "Objective value at epoch t=6 is 0.4724192719689599\n",
      "Objective value at epoch t=7 is 0.477807195647172\n",
      "Objective value at epoch t=8 is 0.47639688081725123\n",
      "Objective value at epoch t=9 is 0.47598406554744904\n",
      "Objective value at epoch t=10 is 0.47345871203939066\n",
      "Objective value at epoch t=11 is 0.4678569986115989\n",
      "Objective value at epoch t=12 is 0.4722630626474807\n",
      "Objective value at epoch t=13 is 0.4690408068513915\n",
      "Objective value at epoch t=14 is 0.46760458421416573\n",
      "Objective value at epoch t=15 is 0.4678527277779304\n",
      "Objective value at epoch t=16 is 0.46565165462218\n",
      "Objective value at epoch t=17 is 0.46553353563167355\n",
      "Objective value at epoch t=18 is 0.46400670767338764\n",
      "Objective value at epoch t=19 is 0.4625963368174449\n",
      "Objective value at epoch t=20 is 0.46148397875194613\n",
      "Objective value at epoch t=21 is 0.4621028390569407\n",
      "Objective value at epoch t=22 is 0.4607889348360845\n",
      "Objective value at epoch t=23 is 0.4602270668819929\n",
      "Objective value at epoch t=24 is 0.4589570926122537\n",
      "Objective value at epoch t=25 is 0.45932779129903734\n",
      "Objective value at epoch t=26 is 0.45877351635083957\n",
      "Objective value at epoch t=27 is 0.4586406230818801\n",
      "Objective value at epoch t=28 is 0.45800207811215427\n",
      "Objective value at epoch t=29 is 0.4577733629433154\n",
      "Objective value at epoch t=30 is 0.4575389175161094\n",
      "Objective value at epoch t=31 is 0.4568510535494797\n",
      "Objective value at epoch t=32 is 0.45696014541653324\n",
      "Objective value at epoch t=33 is 0.4567339473783279\n",
      "Objective value at epoch t=34 is 0.45653410522202514\n",
      "Objective value at epoch t=35 is 0.45632643430809117\n",
      "Objective value at epoch t=36 is 0.4561255566108608\n",
      "Objective value at epoch t=37 is 0.45600590379277356\n",
      "Objective value at epoch t=38 is 0.4558820488927563\n",
      "Objective value at epoch t=39 is 0.45572936206722214\n",
      "Objective value at epoch t=40 is 0.4556312259320855\n",
      "Objective value at epoch t=41 is 0.4555278971777157\n",
      "Objective value at epoch t=42 is 0.4554260741776114\n",
      "Objective value at epoch t=43 is 0.4553332093182453\n",
      "Objective value at epoch t=44 is 0.4552706797882017\n",
      "Objective value at epoch t=45 is 0.4552019374895913\n",
      "Objective value at epoch t=46 is 0.4551375982377797\n",
      "Objective value at epoch t=47 is 0.45507952476756774\n",
      "Objective value at epoch t=48 is 0.45502469981978644\n",
      "Objective value at epoch t=49 is 0.45498503809950164\n",
      "Objective value at epoch t=50 is 0.4549447694738983\n",
      "Objective value at epoch t=51 is 0.4549068932512079\n",
      "Objective value at epoch t=52 is 0.4548717370834017\n",
      "Objective value at epoch t=53 is 0.4548439779255834\n",
      "Objective value at epoch t=54 is 0.4548162673343061\n",
      "Objective value at epoch t=55 is 0.4547922356819753\n",
      "Objective value at epoch t=56 is 0.4547699881384354\n",
      "Objective value at epoch t=57 is 0.4547503485782123\n",
      "Objective value at epoch t=58 is 0.45473252213565435\n",
      "Objective value at epoch t=59 is 0.4547168623261775\n",
      "Objective value at epoch t=60 is 0.45470205752729775\n",
      "Objective value at epoch t=61 is 0.45468923385376314\n",
      "Objective value at epoch t=62 is 0.4546775806456861\n",
      "Objective value at epoch t=63 is 0.45466706632982135\n",
      "Objective value at epoch t=64 is 0.45465746773747284\n",
      "Objective value at epoch t=65 is 0.4546490387783753\n",
      "Objective value at epoch t=66 is 0.45464140247819557\n",
      "Objective value at epoch t=67 is 0.45463452601873433\n",
      "Objective value at epoch t=68 is 0.45462827368120584\n",
      "Objective value at epoch t=69 is 0.4546226098362959\n",
      "Objective value at epoch t=70 is 0.4546175587499623\n",
      "Objective value at epoch t=71 is 0.45461308948551127\n",
      "Objective value at epoch t=72 is 0.45460898959213986\n",
      "Objective value at epoch t=73 is 0.4546053093721726\n",
      "Objective value at epoch t=74 is 0.4546019937995924\n",
      "Objective value at epoch t=75 is 0.45459899913483753\n",
      "Objective value at epoch t=76 is 0.45459632716707415\n",
      "Objective value at epoch t=77 is 0.45459391449745984\n",
      "Objective value at epoch t=78 is 0.45459173469033853\n",
      "Objective value at epoch t=79 is 0.4545897802846347\n",
      "Objective value at epoch t=80 is 0.4545880099695072\n",
      "Objective value at epoch t=81 is 0.4545864355319814\n",
      "Objective value at epoch t=82 is 0.4545850082279557\n",
      "Objective value at epoch t=83 is 0.45458372283089926\n",
      "Objective value at epoch t=84 is 0.45458256651470885\n",
      "Objective value at epoch t=85 is 0.4545815259441012\n",
      "Objective value at epoch t=86 is 0.4545805901909251\n",
      "Objective value at epoch t=87 is 0.45457974643979754\n",
      "Objective value at epoch t=88 is 0.4545789880022498\n",
      "Objective value at epoch t=89 is 0.45457830508329805\n",
      "Objective value at epoch t=90 is 0.45457769141177407\n",
      "Objective value at epoch t=91 is 0.4545771384642487\n",
      "Objective value at epoch t=92 is 0.4545766396614634\n",
      "Objective value at epoch t=93 is 0.45457619255244996\n",
      "Objective value at epoch t=94 is 0.45457578929209597\n",
      "Objective value at epoch t=95 is 0.45457542662816247\n",
      "Objective value at epoch t=96 is 0.4545750998987024\n",
      "Objective value at epoch t=97 is 0.45457480602263944\n",
      "Objective value at epoch t=98 is 0.4545745413793276\n",
      "Objective value at epoch t=99 is 0.4545743034080882\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare GD with SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"281.678111pt\" version=\"1.1\" viewBox=\"0 0 425.047572 281.678111\" width=\"425.047572pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-04T20:10:45.369575</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 281.678111 \nL 425.047572 281.678111 \nL 425.047572 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 73.18125 228.636861 \nL 414.975052 228.636861 \nL 414.975052 9.031163 \nL 73.18125 9.031163 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m6c27206539\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.717332\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(83.627332 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"151.48938\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(141.30938 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"214.261428\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(204.081428 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"277.033476\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(266.853476 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"339.805524\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(329.625524 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"402.577572\" xlink:href=\"#m6c27206539\" y=\"228.636861\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g transform=\"translate(387.307572 247.794361)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epochs -->\n     <g transform=\"translate(208.246901 270.318736)scale(0.2 -0.2)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"306.201172\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3da818cf22\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"222.48061\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.45 -->\n      <g transform=\"translate(30.55625 228.55936)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"180.640238\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.50 -->\n      <g transform=\"translate(30.55625 186.718988)scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"138.799866\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.55 -->\n      <g transform=\"translate(30.55625 144.878616)scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"96.959494\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.60 -->\n      <g transform=\"translate(30.55625 103.038244)scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"55.119122\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.65 -->\n      <g transform=\"translate(30.55625 61.197872)scale(0.16 -0.16)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.18125\" xlink:href=\"#m3da818cf22\" y=\"13.27875\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.70 -->\n      <g transform=\"translate(30.55625 19.3575)scale(0.16 -0.16)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Objective Value -->\n     <g transform=\"translate(22.396875 196.89495)rotate(-90)scale(0.2 -0.2)\">\n      <defs>\n       <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 19.140625 63.90625 8.859375 \nQ 54.734375 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.828125 \nQ 5.609375 19.09375 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nz\n\" id=\"DejaVuSans-79\"/>\n       <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 -0.984375 \nQ 18.40625 -11.421875 14.421875 -16.109375 \nQ 10.453125 -20.796875 1.609375 -20.796875 \nL -1.8125 -20.796875 \nL -1.8125 -13.1875 \nL 0.59375 -13.1875 \nQ 5.71875 -13.1875 7.5625 -10.8125 \nQ 9.421875 -8.453125 9.421875 -0.984375 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-106\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 28.609375 0 \nL 0.78125 72.90625 \nL 11.078125 72.90625 \nL 34.1875 11.53125 \nL 57.328125 72.90625 \nL 67.578125 72.90625 \nL 39.796875 0 \nz\n\" id=\"DejaVuSans-86\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"142.1875\" xlink:href=\"#DejaVuSans-106\"/>\n      <use x=\"169.970703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"231.494141\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"286.474609\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"325.683594\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"353.466797\" xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"412.646484\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"474.169922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"505.957031\" xlink:href=\"#DejaVuSans-86\"/>\n      <use x=\"566.615234\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"627.894531\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"655.677734\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"719.056641\" xlink:href=\"#DejaVuSans-101\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p61aef5248d)\" d=\"M 88.717332 19.01324 \nL 91.855934 111.935347 \nL 94.994537 149.122048 \nL 98.133139 169.084978 \nL 101.271742 181.589633 \nL 104.410344 190.10767 \nL 107.548946 196.213765 \nL 110.687549 200.742803 \nL 113.826151 204.185816 \nL 116.964754 206.852944 \nL 120.103356 208.950282 \nL 123.241958 210.620048 \nL 126.380561 211.963278 \nL 129.519163 213.053448 \nL 132.657766 213.945034 \nL 135.796368 214.679092 \nL 138.93497 215.287008 \nL 142.073573 215.79307 \nL 145.212175 216.216287 \nL 148.350778 216.571676 \nL 151.48938 216.871209 \nL 154.627982 217.124502 \nL 157.766585 217.339337 \nL 160.905187 217.522048 \nL 164.04379 217.677824 \nL 167.182392 217.810936 \nL 170.320994 217.924918 \nL 173.459597 218.022705 \nL 176.598199 218.106746 \nL 179.736802 218.17909 \nL 182.875404 218.241459 \nL 186.014006 218.295305 \nL 189.152609 218.341851 \nL 192.291211 218.382138 \nL 195.429814 218.417047 \nL 198.568416 218.447328 \nL 201.707018 218.47362 \nL 204.845621 218.496472 \nL 207.984223 218.516351 \nL 211.122826 218.533659 \nL 214.261428 218.54874 \nL 217.40003 218.561891 \nL 220.538633 218.573367 \nL 223.677235 218.583389 \nL 226.815838 218.592146 \nL 229.95444 218.599803 \nL 233.093042 218.606503 \nL 236.231645 218.612368 \nL 239.370247 218.617505 \nL 242.50885 218.622007 \nL 245.647452 218.625955 \nL 248.786054 218.629418 \nL 251.924657 218.632457 \nL 255.063259 218.635126 \nL 258.201862 218.637471 \nL 261.340464 218.639532 \nL 264.479066 218.641344 \nL 267.617669 218.642938 \nL 270.756271 218.64434 \nL 273.894874 218.645575 \nL 277.033476 218.646662 \nL 280.172078 218.647619 \nL 283.310681 218.648463 \nL 286.449283 218.649207 \nL 289.587886 218.649863 \nL 292.726488 218.650442 \nL 295.86509 218.650953 \nL 299.003693 218.651404 \nL 302.142295 218.651802 \nL 305.280898 218.652153 \nL 308.4195 218.652464 \nL 311.558102 218.652738 \nL 314.696705 218.652981 \nL 317.835307 218.653195 \nL 320.97391 218.653385 \nL 324.112512 218.653553 \nL 327.251114 218.653701 \nL 330.389717 218.653833 \nL 333.528319 218.653949 \nL 336.666922 218.654052 \nL 339.805524 218.654143 \nL 342.944127 218.654224 \nL 346.082729 218.654296 \nL 349.221331 218.654359 \nL 352.359934 218.654415 \nL 355.498536 218.654465 \nL 358.637139 218.654509 \nL 361.775741 218.654549 \nL 364.914343 218.654583 \nL 368.052946 218.654614 \nL 371.191548 218.654642 \nL 374.330151 218.654666 \nL 377.468753 218.654687 \nL 380.607355 218.654707 \nL 383.745958 218.654724 \nL 386.88456 218.654739 \nL 390.023163 218.654752 \nL 393.161765 218.654764 \nL 396.300367 218.654775 \nL 399.43897 218.654784 \n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:14.8,6.4;stroke-dashoffset:0;stroke-width:4;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p61aef5248d)\" d=\"M 88.717332 157.751114 \nL 91.855934 177.369085 \nL 94.994537 182.079486 \nL 98.133139 186.962651 \nL 101.271742 189.329731 \nL 104.410344 191.839377 \nL 107.548946 203.719996 \nL 110.687549 199.211341 \nL 113.826151 200.391503 \nL 116.964754 200.73695 \nL 120.103356 202.850185 \nL 123.241958 207.53774 \nL 126.380561 203.850713 \nL 129.519163 206.547121 \nL 132.657766 207.748963 \nL 135.796368 207.541314 \nL 138.93497 209.383189 \nL 142.073573 209.482032 \nL 145.212175 210.759692 \nL 148.350778 211.939901 \nL 151.48938 212.870731 \nL 154.627982 212.352864 \nL 157.766585 213.452349 \nL 160.905187 213.922524 \nL 164.04379 214.985248 \nL 167.182392 214.675045 \nL 170.320994 215.138866 \nL 173.459597 215.250072 \nL 176.598199 215.784411 \nL 179.736802 215.975802 \nL 182.875404 216.171987 \nL 186.014006 216.747597 \nL 189.152609 216.656308 \nL 192.291211 216.845592 \nL 195.429814 217.012822 \nL 198.568416 217.186602 \nL 201.707018 217.354698 \nL 204.845621 217.454825 \nL 207.984223 217.558467 \nL 211.122826 217.686237 \nL 214.261428 217.768358 \nL 217.40003 217.854824 \nL 220.538633 217.94003 \nL 223.677235 218.01774 \nL 226.815838 218.070066 \nL 229.95444 218.12759 \nL 233.093042 218.181429 \nL 236.231645 218.230026 \nL 239.370247 218.275903 \nL 242.50885 218.309093 \nL 245.647452 218.34279 \nL 248.786054 218.374485 \nL 251.924657 218.403904 \nL 255.063259 218.427133 \nL 258.201862 218.450321 \nL 261.340464 218.470431 \nL 264.479066 218.489048 \nL 267.617669 218.505483 \nL 270.756271 218.5204 \nL 273.894874 218.533504 \nL 277.033476 218.545893 \nL 280.172078 218.556624 \nL 283.310681 218.566375 \nL 286.449283 218.575174 \nL 289.587886 218.583206 \nL 292.726488 218.590259 \nL 295.86509 218.59665 \nL 299.003693 218.602404 \nL 302.142295 218.607636 \nL 305.280898 218.612375 \nL 308.4195 218.616602 \nL 311.558102 218.620342 \nL 314.696705 218.623773 \nL 317.835307 218.626853 \nL 320.97391 218.629627 \nL 324.112512 218.632133 \nL 327.251114 218.634369 \nL 330.389717 218.636388 \nL 333.528319 218.638212 \nL 336.666922 218.639847 \nL 339.805524 218.641329 \nL 342.944127 218.642646 \nL 346.082729 218.643841 \nL 349.221331 218.644916 \nL 352.359934 218.645884 \nL 355.498536 218.646755 \nL 358.637139 218.647538 \nL 361.775741 218.648244 \nL 364.914343 218.648878 \nL 368.052946 218.64945 \nL 371.191548 218.649963 \nL 374.330151 218.650426 \nL 377.468753 218.650844 \nL 380.607355 218.651218 \nL 383.745958 218.651555 \nL 386.88456 218.651859 \nL 390.023163 218.652132 \nL 393.161765 218.652378 \nL 396.300367 218.652599 \nL 399.43897 218.652799 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:2;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 73.18125 228.636861 \nL 73.18125 9.031163 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 414.975052 228.636861 \nL 414.975052 9.031163 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 73.18125 228.636861 \nL 414.975052 228.636861 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 73.18125 9.031163 \nL 414.975052 9.031163 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 293.381302 83.743663 \nL 400.975052 83.743663 \nQ 404.975052 83.743663 404.975052 79.743663 \nL 404.975052 23.031163 \nQ 404.975052 19.031163 400.975052 19.031163 \nL 293.381302 19.031163 \nQ 289.381302 19.031163 289.381302 23.031163 \nL 289.381302 79.743663 \nQ 289.381302 83.743663 293.381302 83.743663 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 297.381302 35.228038 \nL 337.381302 35.228038 \n\" style=\"fill:none;stroke:#0000ff;stroke-dasharray:14.8,6.4;stroke-dashoffset:0;stroke-width:4;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_15\">\n     <!-- GD -->\n     <g transform=\"translate(353.381302 42.228038)scale(0.2 -0.2)\">\n      <defs>\n       <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n       <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-71\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-68\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 297.381302 64.584288 \nL 337.381302 64.584288 \n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:2;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_16\">\n     <!-- SGD -->\n     <g transform=\"translate(353.381302 71.584288)scale(0.2 -0.2)\">\n      <defs>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"63.476562\" xlink:href=\"#DejaVuSans-71\"/>\n      <use x=\"140.966797\" xlink:href=\"#DejaVuSans-68\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p61aef5248d\">\n   <rect height=\"219.605698\" width=\"341.793802\" x=\"73.18125\" y=\"9.031163\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1], ['GD', 'SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = numpy.dot(X, w)\n",
    "    f = numpy.sign(xw)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training classification error is 0.2078125\n"
     ]
    }
   ],
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = numpy.abs(f_train - y_train) / 2\n",
    "error_train = numpy.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test classification error is 0.296875\n"
     ]
    }
   ],
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = numpy.abs(f_test - y_test) / 2\n",
    "error_test = numpy.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mini-batch SGD (fill the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Compute the objective $Q_I$ and its gradient using a batch of samples\n",
    "\n",
    "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of stochastic_objective_gradient\n",
    "    # Use matrix-vector multiplication; do not use FOR LOOP of vector-vector multiplications\n",
    "    yx = yi.transpose() * xi    # b-by-d matrix\n",
    "    yxw = float( numpy.dot(yx, w) ) # b-by-1 matrix\n",
    "    cumul = numpy.log(1 + numpy.exp(-yxw)) # b-by-1 matrix\n",
    "\n",
    "    # Compute the object function\n",
    "    loss = (1/b)*numpy.sum(cumul) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "\n",
    "    # Compute the gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g_sum = (1/b) * numpy.sum( g_loss ) # scalar \n",
    "    g = g_sum + lam * w # d-by-1 matrix\n",
    "\n",
    "    # Return\n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Implement mini-batch SGD\n",
    "\n",
    "Hints:\n",
    "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
    "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_stochastic_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def mb_sgd(x, y, lam, b, stepsize, max_epoch=100, w=None):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of sgd\n",
    "    # Record one objective value per epoch (not per iteration!)\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "\n",
    "        # Stochastic over the mini batches\n",
    "        last_index = 0\n",
    "        objval = 0\n",
    "        for i in range(b, n+1, b):\n",
    "            x_test = x_rand[last_index:b, :] # b-by-d matrix\n",
    "            y_test = y_rand[last_index:b, :] # b-by-1 matrix\n",
    "\n",
    "            obj, g = mb_stochastic_objective_gradient(w, x_test, y_test, lam, b )\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        stepsize *= 0.9\n",
    "        objval /= (n/b)\n",
    "        objvals[t] = objval\n",
    "        print(\"Object value at epoch t={} is {}\".format( t, objval ))\n",
    "\n",
    "    return w, objvals\n",
    "\n",
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "# def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "#     n, d = x.shape\n",
    "#     objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "#     if w is None:\n",
    "#         w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "#     for t in range(max_epoch):\n",
    "#         # randomly shuffle the samples\n",
    "#         rand_indices = numpy.random.permutation(n)\n",
    "#         x_rand = x[rand_indices, :]\n",
    "#         y_rand = y[rand_indices, :]\n",
    "        \n",
    "#         objval = 0 # accumulate the objective values\n",
    "#         for i in range(n):\n",
    "#             xi = x_rand[i, :] # 1-by-d matrix\n",
    "#             yi = float(y_rand[i, :]) # scalar\n",
    "#             obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "#             objval += obj\n",
    "#             w -= stepsize * g\n",
    "        \n",
    "#         stepsize *= 0.9 # decrease step size\n",
    "#         objval /= n\n",
    "#         objvals[t] = objval\n",
    "#         print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "#     return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Run MB-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Object value at epoch t=0 is 0.001395560477893854\n",
      "Object value at epoch t=1 is 0.0002597605393089537\n",
      "Object value at epoch t=2 is 3.163712465337299e-07\n",
      "Object value at epoch t=3 is 0.006448183482582965\n",
      "Object value at epoch t=4 is 0.0035555797088850836\n",
      "Object value at epoch t=5 is 0.00010821838769529899\n",
      "Object value at epoch t=6 is 0.004059193636434604\n",
      "Object value at epoch t=7 is 0.011550602628195804\n",
      "Object value at epoch t=8 is 0.00014861768434265996\n",
      "Object value at epoch t=9 is 0.0002328618412911155\n",
      "Object value at epoch t=10 is 0.009081652389354962\n",
      "Object value at epoch t=11 is 0.011666887204004339\n",
      "Object value at epoch t=12 is 3.505471318130217e-05\n",
      "Object value at epoch t=13 is 0.007956195386114338\n",
      "Object value at epoch t=14 is 5.205183294975094e-05\n",
      "Object value at epoch t=15 is 9.576295057635013e-05\n",
      "Object value at epoch t=16 is 0.008355251616078804\n",
      "Object value at epoch t=17 is 4.534747644842854e-05\n",
      "Object value at epoch t=18 is 2.784627844467808e-05\n",
      "Object value at epoch t=19 is 0.016414510449174195\n",
      "Object value at epoch t=20 is 0.004314439462633499\n",
      "Object value at epoch t=21 is 0.006611480858810128\n",
      "Object value at epoch t=22 is 2.7380581072263005e-05\n",
      "Object value at epoch t=23 is 2.504336304869303e-06\n",
      "Object value at epoch t=24 is 0.016567253367217167\n",
      "Object value at epoch t=25 is 0.005114652682992428\n",
      "Object value at epoch t=26 is 0.0010665136304939264\n",
      "Object value at epoch t=27 is 0.0013970575673326556\n",
      "Object value at epoch t=28 is 0.0015882901458556694\n",
      "Object value at epoch t=29 is 9.786604247233549e-05\n",
      "Object value at epoch t=30 is 0.0011905781394932334\n",
      "Object value at epoch t=31 is 7.557873311607317e-05\n",
      "Object value at epoch t=32 is 9.775819954560255e-06\n",
      "Object value at epoch t=33 is 2.5790236863165517e-05\n",
      "Object value at epoch t=34 is 2.9326314528625026e-06\n",
      "Object value at epoch t=35 is 1.3247816037148208e-05\n",
      "Object value at epoch t=36 is 0.014539604953292281\n",
      "Object value at epoch t=37 is 0.0034769558137552983\n",
      "Object value at epoch t=38 is 0.05139651280074135\n",
      "Object value at epoch t=39 is 0.001648628796206781\n",
      "Object value at epoch t=40 is 0.0030870219759720446\n",
      "Object value at epoch t=41 is 0.002135749079861326\n",
      "Object value at epoch t=42 is 0.004072405511106581\n",
      "Object value at epoch t=43 is 0.000834151562422575\n",
      "Object value at epoch t=44 is 0.0012115782691538408\n",
      "Object value at epoch t=45 is 0.009896149427776389\n",
      "Object value at epoch t=46 is 0.02944528597340999\n",
      "Object value at epoch t=47 is 0.0019732493425070282\n",
      "Object value at epoch t=48 is 0.00022030297543765707\n",
      "Object value at epoch t=49 is 0.001124560616658171\n",
      "Object value at epoch t=50 is 0.005217214438559619\n",
      "Object value at epoch t=51 is 0.03216725672883769\n",
      "Object value at epoch t=52 is 0.0010869029599412153\n",
      "Object value at epoch t=53 is 0.011048475602199603\n",
      "Object value at epoch t=54 is 0.0023393745757118952\n",
      "Object value at epoch t=55 is 0.005775369185749163\n",
      "Object value at epoch t=56 is 0.00038934673559112083\n",
      "Object value at epoch t=57 is 0.0012689698169271932\n",
      "Object value at epoch t=58 is 0.012853053006764776\n",
      "Object value at epoch t=59 is 0.010754981591448666\n",
      "Object value at epoch t=60 is 0.014755966535360644\n",
      "Object value at epoch t=61 is 0.0006793546252667471\n",
      "Object value at epoch t=62 is 0.003169993156617377\n",
      "Object value at epoch t=63 is 0.0005598308014168094\n",
      "Object value at epoch t=64 is 0.006861645835075388\n",
      "Object value at epoch t=65 is 0.0018252041460213564\n",
      "Object value at epoch t=66 is 0.012015054198098308\n",
      "Object value at epoch t=67 is 0.0037062558467257437\n",
      "Object value at epoch t=68 is 0.006879335100641375\n",
      "Object value at epoch t=69 is 0.0018458486052740923\n",
      "Object value at epoch t=70 is 0.0025350542007955977\n",
      "Object value at epoch t=71 is 0.0003598313193267797\n",
      "Object value at epoch t=72 is 0.00835632279132339\n",
      "Object value at epoch t=73 is 0.0018735144364997874\n",
      "Object value at epoch t=74 is 0.008018733586737202\n",
      "Object value at epoch t=75 is 0.00985295743388812\n",
      "Object value at epoch t=76 is 0.007857912459234924\n",
      "Object value at epoch t=77 is 0.014064854999285243\n",
      "Object value at epoch t=78 is 0.0052366700295780454\n",
      "Object value at epoch t=79 is 0.0027134993598527434\n",
      "Object value at epoch t=80 is 0.0009686657836974055\n",
      "Object value at epoch t=81 is 0.005484774288022852\n",
      "Object value at epoch t=82 is 0.04431140600710727\n",
      "Object value at epoch t=83 is 0.0014065244548219866\n",
      "Object value at epoch t=84 is 0.008144671064858713\n",
      "Object value at epoch t=85 is 0.0004017587720675636\n",
      "Object value at epoch t=86 is 0.0138203511423996\n",
      "Object value at epoch t=87 is 0.007853019985939968\n",
      "Object value at epoch t=88 is 0.004750120246088377\n",
      "Object value at epoch t=89 is 0.0019723106129701344\n",
      "Object value at epoch t=90 is 0.0002969768332766832\n",
      "Object value at epoch t=91 is 0.0008450367732732196\n",
      "Object value at epoch t=92 is 0.0007250789709226831\n",
      "Object value at epoch t=93 is 0.00231108869664575\n",
      "Object value at epoch t=94 is 0.02214428187776786\n",
      "Object value at epoch t=95 is 0.0008220660459519293\n",
      "Object value at epoch t=96 is 0.02781870087546346\n",
      "Object value at epoch t=97 is 0.02548306003586674\n",
      "Object value at epoch t=98 is 0.013182919960763307\n",
      "Object value at epoch t=99 is 0.01100766919089237\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd8 = mb_sgd(x_train, y_train, lam, b, stepsize, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MB-SGD with batch size b=64\n",
    "lam = 1E-6 # do not change\n",
    "b = 64 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd64 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot and compare GD, SGD, and MB-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to compare the following algorithms:\n",
    "\n",
    "- Gradient descent (GD)\n",
    "\n",
    "- SGD\n",
    "\n",
    "- MB-SGD with b=8\n",
    "\n",
    "- MB-SGD with b=64\n",
    "\n",
    "Follow the code in Section 4 to plot ```objective function value``` against ```epochs```. There should be four curves in the plot; each curve corresponds to one algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Logistic regression with $\\ell_2$-norm regularization is a strongly convex optimization problem. All the algorithms will converge to the same solution. **In the end, the ``objective function value`` of the 4 algorithms will be the same. If not the same, your implementation must be wrong. Do NOT submit wrong code and wrong result!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 curves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}